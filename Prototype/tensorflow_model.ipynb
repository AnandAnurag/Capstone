{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !pip install --user --upgrade tensorflow==1.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import calendar\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0-rc1'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "books = pd.read_csv(r\"../Dataset/Final/BX-Books.csv\")\n",
    "ratings = pd.read_csv(r\"../Dataset/Final/BX-Book-Ratings.csv\")\n",
    "users = pd.read_csv(r\"../Dataset/Final/BX-Users.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276725</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>276726</td>\n",
       "      <td>0155061224</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276727</td>\n",
       "      <td>0446520802</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>276729</td>\n",
       "      <td>052165615X</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>276729</td>\n",
       "      <td>0521795028</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User-ID        ISBN  Book-Rating\n",
       "0   276725  034545104X            0\n",
       "1   276726  0155061224            5\n",
       "2   276727  0446520802            0\n",
       "3   276729  052165615X            3\n",
       "4   276729  0521795028            6"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Airmont</td>\n",
       "      <td>New York</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Stockton</td>\n",
       "      <td>California</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Moscow</td>\n",
       "      <td>Moscow</td>\n",
       "      <td>Russia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Porto</td>\n",
       "      <td>Norte</td>\n",
       "      <td>Portugal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Farnborough</td>\n",
       "      <td>England</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User-ID   Age         City       State         Country\n",
       "0        1  20.0      Airmont    New York   United States\n",
       "1        2  18.0     Stockton  California   United States\n",
       "2        3  21.0       Moscow      Moscow          Russia\n",
       "3        4  17.0        Porto       Norte        Portugal\n",
       "4        5  23.0  Farnborough     England  United Kingdom"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "      <th>g_year-of-publication</th>\n",
       "      <th>g_categories</th>\n",
       "      <th>g_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0195153448</td>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>2002</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>2003</td>\n",
       "      <td>Social Science</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>2001</td>\n",
       "      <td>Actresses</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991</td>\n",
       "      <td>HarperPerennial</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>1983</td>\n",
       "      <td>1940-1949</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0393045218</td>\n",
       "      <td>The Mummies of Urumchi</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "      <td>1999</td>\n",
       "      <td>W. W. Norton &amp;amp; Company</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>1999</td>\n",
       "      <td>Design</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ISBN                                         Book-Title  \\\n",
       "0  0195153448                                Classical Mythology   \n",
       "1  0002005018                                       Clara Callan   \n",
       "2  0060973129                               Decision in Normandy   \n",
       "3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "4  0393045218                             The Mummies of Urumchi   \n",
       "\n",
       "            Book-Author  Year-Of-Publication                   Publisher  \\\n",
       "0    Mark P. O. Morford                 2002     Oxford University Press   \n",
       "1  Richard Bruce Wright                 2001       HarperFlamingo Canada   \n",
       "2          Carlo D'Este                 1991             HarperPerennial   \n",
       "3      Gina Bari Kolata                 1999        Farrar Straus Giroux   \n",
       "4       E. J. W. Barber                 1999  W. W. Norton &amp; Company   \n",
       "\n",
       "                                         Image-URL-S  \\\n",
       "0  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0060973129.0...   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...   \n",
       "4  http://images.amazon.com/images/P/0393045218.0...   \n",
       "\n",
       "                                         Image-URL-M  \\\n",
       "0  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0060973129.0...   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...   \n",
       "4  http://images.amazon.com/images/P/0393045218.0...   \n",
       "\n",
       "                                         Image-URL-L g_year-of-publication  \\\n",
       "0  http://images.amazon.com/images/P/0195153448.0...                  2003   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...                  2001   \n",
       "2  http://images.amazon.com/images/P/0060973129.0...                  1983   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...                  1999   \n",
       "4  http://images.amazon.com/images/P/0393045218.0...                  1999   \n",
       "\n",
       "     g_categories  g_processed  \n",
       "0  Social Science            1  \n",
       "1       Actresses            1  \n",
       "2       1940-1949            1  \n",
       "3         Medical            1  \n",
       "4          Design            1  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_data_df = ratings.merge(books,on='ISBN').merge(users,on='User-ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User-ID                  1031173\n",
       "ISBN                     1031173\n",
       "Book-Rating              1031173\n",
       "Book-Title               1031173\n",
       "Book-Author              1031172\n",
       "Year-Of-Publication      1031173\n",
       "Publisher                1031171\n",
       "Image-URL-S              1031173\n",
       "Image-URL-M              1031173\n",
       "Image-URL-L              1031173\n",
       "g_year-of-publication    1031173\n",
       "g_categories             1031173\n",
       "g_processed              1031173\n",
       "Age                      1031173\n",
       "City                     1031173\n",
       "State                    1031173\n",
       "Country                  1031173\n",
       "dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "useful_data_df = full_data_df[['City', 'State', 'Country', 'Age', 'Book-Author', 'Year-Of-Publication', 'Publisher', 'Book-Rating']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Book-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tyler</td>\n",
       "      <td>Texas</td>\n",
       "      <td>United States</td>\n",
       "      <td>21.0</td>\n",
       "      <td>M. J. Rose</td>\n",
       "      <td>2002</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cincinnati</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>United States</td>\n",
       "      <td>23.0</td>\n",
       "      <td>M. J. Rose</td>\n",
       "      <td>2002</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cincinnati</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>United States</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Orson Scott Card</td>\n",
       "      <td>1986</td>\n",
       "      <td>Tor Books</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cincinnati</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>United States</td>\n",
       "      <td>23.0</td>\n",
       "      <td>TRUMAN CAPOTE</td>\n",
       "      <td>1994</td>\n",
       "      <td>Vintage</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cincinnati</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>United States</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Rebecca Wells</td>\n",
       "      <td>1996</td>\n",
       "      <td>HarperCollins</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         City  State        Country   Age       Book-Author  \\\n",
       "0       Tyler  Texas  United States  21.0        M. J. Rose   \n",
       "1  Cincinnati   Ohio  United States  23.0        M. J. Rose   \n",
       "2  Cincinnati   Ohio  United States  23.0  Orson Scott Card   \n",
       "3  Cincinnati   Ohio  United States  23.0     TRUMAN CAPOTE   \n",
       "4  Cincinnati   Ohio  United States  23.0     Rebecca Wells   \n",
       "\n",
       "   Year-Of-Publication         Publisher  Book-Rating  \n",
       "0                 2002  Ballantine Books            0  \n",
       "1                 2002  Ballantine Books            5  \n",
       "2                 1986         Tor Books            9  \n",
       "3                 1994           Vintage            8  \n",
       "4                 1996     HarperCollins            9  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "useful_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getLabelEncodedColumn(col, df):\n",
    "    le = LabelEncoder()\n",
    "    return le.fit_transform(df[col].values).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City                   1031170\n",
       "State                  1031170\n",
       "Country                1031170\n",
       "Age                    1031170\n",
       "Book-Author            1031170\n",
       "Year-Of-Publication    1031170\n",
       "Publisher              1031170\n",
       "Book-Rating            1031170\n",
       "dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "useful_data_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "useful_data_df['Book-Author-Enc'] = getLabelEncodedColumn('Book-Author', useful_data_df)\n",
    "useful_data_df['City-Enc'] = getLabelEncodedColumn('City', useful_data_df)\n",
    "useful_data_df['State-Enc'] = getLabelEncodedColumn('State', useful_data_df)\n",
    "useful_data_df['Country-Enc'] = getLabelEncodedColumn('Country', useful_data_df)\n",
    "useful_data_df['Publisher-Enc'] = getLabelEncodedColumn('Publisher', useful_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Book-Rating</th>\n",
       "      <th>Book-Author-Enc</th>\n",
       "      <th>City-Enc</th>\n",
       "      <th>State-Enc</th>\n",
       "      <th>Country-Enc</th>\n",
       "      <th>Publisher-Enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tyler</td>\n",
       "      <td>Texas</td>\n",
       "      <td>United States</td>\n",
       "      <td>21.0</td>\n",
       "      <td>M. J. Rose</td>\n",
       "      <td>2002</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>0</td>\n",
       "      <td>61693</td>\n",
       "      <td>6860</td>\n",
       "      <td>927</td>\n",
       "      <td>157</td>\n",
       "      <td>1391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cincinnati</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>United States</td>\n",
       "      <td>23.0</td>\n",
       "      <td>M. J. Rose</td>\n",
       "      <td>2002</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>5</td>\n",
       "      <td>61693</td>\n",
       "      <td>1526</td>\n",
       "      <td>686</td>\n",
       "      <td>157</td>\n",
       "      <td>1391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cincinnati</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>United States</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Orson Scott Card</td>\n",
       "      <td>1986</td>\n",
       "      <td>Tor Books</td>\n",
       "      <td>9</td>\n",
       "      <td>73674</td>\n",
       "      <td>1526</td>\n",
       "      <td>686</td>\n",
       "      <td>157</td>\n",
       "      <td>14901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cincinnati</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>United States</td>\n",
       "      <td>23.0</td>\n",
       "      <td>TRUMAN CAPOTE</td>\n",
       "      <td>1994</td>\n",
       "      <td>Vintage</td>\n",
       "      <td>8</td>\n",
       "      <td>93471</td>\n",
       "      <td>1526</td>\n",
       "      <td>686</td>\n",
       "      <td>157</td>\n",
       "      <td>15650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cincinnati</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>United States</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Rebecca Wells</td>\n",
       "      <td>1996</td>\n",
       "      <td>HarperCollins</td>\n",
       "      <td>9</td>\n",
       "      <td>80510</td>\n",
       "      <td>1526</td>\n",
       "      <td>686</td>\n",
       "      <td>157</td>\n",
       "      <td>6614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         City  State        Country   Age       Book-Author  \\\n",
       "0       Tyler  Texas  United States  21.0        M. J. Rose   \n",
       "1  Cincinnati   Ohio  United States  23.0        M. J. Rose   \n",
       "2  Cincinnati   Ohio  United States  23.0  Orson Scott Card   \n",
       "3  Cincinnati   Ohio  United States  23.0     TRUMAN CAPOTE   \n",
       "4  Cincinnati   Ohio  United States  23.0     Rebecca Wells   \n",
       "\n",
       "   Year-Of-Publication         Publisher  Book-Rating  Book-Author-Enc  \\\n",
       "0                 2002  Ballantine Books            0            61693   \n",
       "1                 2002  Ballantine Books            5            61693   \n",
       "2                 1986         Tor Books            9            73674   \n",
       "3                 1994           Vintage            8            93471   \n",
       "4                 1996     HarperCollins            9            80510   \n",
       "\n",
       "   City-Enc  State-Enc  Country-Enc  Publisher-Enc  \n",
       "0      6860        927          157           1391  \n",
       "1      1526        686          157           1391  \n",
       "2      1526        686          157          14901  \n",
       "3      1526        686          157          15650  \n",
       "4      1526        686          157           6614  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "useful_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_df = useful_data_df.filter(['Age', 'Year-Of-Publication','Publisher-Enc',\n",
    "                                   'Book-Author-Enc', 'City-Enc','State-Enc', 'Book-Rating']).head(7000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = training_df.drop('Book-Rating', axis=1), training_df[['Book-Rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTfDataset(X, y):\n",
    "    features = ['Age', 'Year-Of-Publication','Publisher-Enc',\n",
    "                                   'Book-Author-Enc', 'City-Enc','State-Enc']\n",
    "    target = 'Book-Rating'\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "                (\n",
    "                    tf.cast(X.values, tf.float32),\n",
    "                    tf.cast(y.values, tf.float32)\n",
    "                )\n",
    "            )        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "def getOneHotEncoding(column):\n",
    "    enc = OneHotEncoder(handle_unknown='ignore')\n",
    "    enc.fit_transform(useful_data_df[column].values.reshape(-1,  1))\n",
    "    return enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def oneHotCodedSparseMatrix():\n",
    "    return {\n",
    "        'author': getOneHotEncoding('Book-Author-Enc'),\n",
    "        'city': getOneHotEncoding('City-Enc'),\n",
    "        'state': getOneHotEncoding('State-Enc')\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def embeddingsInputLen():\n",
    "    ohcsm = oneHotCodedSparseMatrix()\n",
    "    return {\n",
    "        'author': len(ohcsm['author'].active_features_),\n",
    "        'city': len(ohcsm['city'].active_features_),\n",
    "        'state': len(ohcsm['state'].active_features_)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'author': 101590, 'city': 7574, 'state': 1065}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddingsLength = embeddingsInputLen()\n",
    "embeddingsLength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RUN_NAME = calendar.timegm(time.gmtime())\n",
    "\n",
    "learning_rate = 0.001\n",
    "training_epochs = 30\n",
    "\n",
    "number_of_inputs = 5\n",
    "number_of_outputs = 1\n",
    "\n",
    "layer_1_nodes = 5\n",
    "layer_2_nodes = 25\n",
    "layer_3_nodes = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getInputLayers(name):\n",
    "    return tf.placeholder(tf.float64, shape=(None, 1), name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "batchSize = 256\n",
    "batchedTrainingDataset = getTfDataset(X_train, y_train).batch(batchSize)\n",
    "batchedTestDataset = getTfDataset(X_test, y_test).batch(batchSize)\n",
    "train_iterator = batchedTrainingDataset.make_initializable_iterator()\n",
    "test_iterator = batchedTestDataset.make_initializable_iterator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Layer: Age, City, State, Author, Year of Publish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_age = getInputLayers('input_age')\n",
    "input_state = getInputLayers('input_state') \n",
    "input_author = getInputLayers('input_author')\n",
    "input_city = getInputLayers('input_city')\n",
    "input_year = getInputLayers('input_year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings: City, State, Author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights_city = tf.get_variable(name=\"city_emb_wt\", shape=[embeddingsLength['city'], 2], initializer=tf.contrib.layers.xavier_initializer(), dtype=tf.float64)\n",
    "encoded_city_ohv = tf.one_hot(tf.cast(input_city, tf.int64), embeddingsLength['city'])\n",
    "encoded_city = tf.reshape(encoded_city_ohv,(-1, embeddingsLength['city']))\n",
    "embedding_city_output = tf.nn.relu(tf.matmul(tf.cast(encoded_city, tf.float64), weights_city))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights_state = tf.get_variable(name=\"state_emb_wt\", shape=[embeddingsLength['state'], 2], initializer=tf.contrib.layers.xavier_initializer(), dtype=tf.float64)\n",
    "encoded_state_ohv = tf.one_hot(tf.cast(input_state, tf.int64), embeddingsLength['state'])\n",
    "encoded_state = tf.reshape(encoded_state_ohv,(-1, embeddingsLength['state']))\n",
    "embedding_state_output = tf.nn.relu(tf.matmul(tf.cast(encoded_state, tf.float64), weights_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights_author = tf.get_variable(name=\"author_emb_wt\", shape=[embeddingsLength['author'], 2], initializer=tf.contrib.layers.xavier_initializer(), dtype=tf.float64)\n",
    "encoded_author_ohv = tf.one_hot(tf.cast(input_author, tf.int64), embeddingsLength['author'])\n",
    "encoded_author = tf.reshape(encoded_author_ohv,(-1, embeddingsLength['author']))\n",
    "embedding_author_output = tf.nn.relu(tf.matmul(tf.cast(encoded_author, tf.float64), weights_author))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_x = tf.concat([input_age, embedding_city_output, embedding_state_output, embedding_author_output, input_year], axis=1)\n",
    "weights_1 = tf.get_variable(name=\"weights1\", shape=[8, layer_1_nodes], initializer=tf.contrib.layers.xavier_initializer(), dtype=tf.float64)\n",
    "biases_1 = tf.get_variable(name=\"biases1\", shape=[layer_1_nodes], initializer=tf.zeros_initializer(), dtype=tf.float64)\n",
    "layer_1_output = tf.nn.relu(tf.matmul(input_x, weights_1) + biases_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights_2 = tf.get_variable(name=\"weights2\", shape=[layer_1_nodes, layer_2_nodes], initializer=tf.contrib.layers.xavier_initializer(), dtype=tf.float64)\n",
    "biases_2 = tf.get_variable(name=\"biases2\", shape=[layer_2_nodes], initializer=tf.zeros_initializer(), dtype=tf.float64)\n",
    "layer_2_output = tf.nn.relu(tf.matmul(layer_1_output, weights_2) + biases_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights_3 = tf.get_variable(name=\"weights3\", shape=[layer_2_nodes, layer_3_nodes], initializer=tf.contrib.layers.xavier_initializer(), dtype=tf.float64)\n",
    "biases_3 = tf.get_variable(name=\"biases3\", shape=[layer_3_nodes], initializer=tf.zeros_initializer(), dtype=tf.float64)\n",
    "layer_3_output = tf.nn.relu(tf.matmul(layer_2_output, weights_3) + biases_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights_o = tf.get_variable(\"weights4\", shape=[layer_3_nodes, number_of_outputs], initializer=tf.contrib.layers.xavier_initializer(), dtype=tf.float64)\n",
    "biases_o = tf.get_variable(name=\"biases4\", shape=[number_of_outputs], initializer=tf.zeros_initializer(), dtype=tf.float64)\n",
    "prediction = tf.matmul(layer_3_output, weights_o) + biases_o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actual_y = tf.placeholder(tf.float64, shape=(None, 1), name=\"Actual_Y\")\n",
    "cost = tf.reduce_mean(tf.squared_difference(prediction, actual_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('logging'):\n",
    "    tf.summary.scalar('current_cost', cost)\n",
    "    summary = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getFeedDict(batch, batchSize, sess):\n",
    "    features = batch[0].eval(session=sess)\n",
    "    age = features[:,0].reshape(-1, 1)\n",
    "    yop = features[:,1].reshape(-1, 1)\n",
    "    pub = features[:,2].reshape(-1, 1)\n",
    "    atr = features[:,3].reshape(-1, 1)\n",
    "    city = features[:,4].reshape(-1, 1)\n",
    "    state = features[:,5].reshape(-1, 1)\n",
    "    output = batch[1].eval(session=sess)\n",
    "    actualBatchSize = features.shape[0]\n",
    "    print('Required Batch Size: {}, Actual Batch Size: age{}, yop{}, atr{}, city{}, state{}, output{}'.format(batchSize, age.shape, yop.shape, atr.shape, city.shape, state.shape, output.shape))\n",
    "    if batchSize > actualBatchSize:\n",
    "        shape = [batchSize - actualBatchSize, 1]\n",
    "        age = padArrayWithZeros(shape, age)\n",
    "        yop = padArrayWithZeros(shape, yop)\n",
    "        pub = padArrayWithZeros(shape, pub)\n",
    "        atr = padArrayWithZeros(shape, atr)\n",
    "        city = padArrayWithZeros(shape, city)\n",
    "        state = padArrayWithZeros(shape, state)\n",
    "        print\n",
    "        output = padArrayWithZeros(shape, output)\n",
    "        print('Readjusted: age{}, yop{}, atr{}, city{}, state{}, output{}'.format(age.shape, yop.shape, atr.shape, city.shape, state.shape, output.shape))\n",
    "    return {input_age: age, input_year: yop, input_author: atr, input_city: city, input_state: state, actual_y: output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def padArrayWithZeros(shape, arr):\n",
    "    zeroPad = np.zeros(shape)\n",
    "    return np.concatenate([arr, zeroPad], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required Batch Size: 256, Actual Batch Size: age(256, 1), yop(256, 1), atr(256, 1), city(256, 1), state(256, 1), output(256, 1)\n",
      "Batch: 1 Cost: 116.84249006052922\n",
      "Required Batch Size: 256, Actual Batch Size: age(256, 1), yop(256, 1), atr(256, 1), city(256, 1), state(256, 1), output(256, 1)\n",
      "Batch: 2 Cost: 123.58526180628435\n",
      "Required Batch Size: 256, Actual Batch Size: age(256, 1), yop(256, 1), atr(256, 1), city(256, 1), state(256, 1), output(256, 1)\n",
      "Batch: 3 Cost: 118.8998738040132\n",
      "Required Batch Size: 256, Actual Batch Size: age(256, 1), yop(256, 1), atr(256, 1), city(256, 1), state(256, 1), output(256, 1)\n",
      "Batch: 4 Cost: 117.57023004752958\n",
      "Required Batch Size: 256, Actual Batch Size: age(256, 1), yop(256, 1), atr(256, 1), city(256, 1), state(256, 1), output(6, 1)\n",
      "Exception Occurred Incompatible shapes: [256,1] vs. [6,1]\n",
      "\t [[Node: SquaredDifference = SquaredDifference[T=DT_DOUBLE, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](add_3, _arg_Actual_Y_0_0)]]\n",
      "\n",
      "Caused by op 'SquaredDifference', defined at:\n",
      "  File \"/usr/local/anaconda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/local/anaconda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/anaconda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/anaconda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n",
      "    ioloop.IOLoop.instance().start()\n",
      "  File \"/usr/local/anaconda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n",
      "    super(ZMQIOLoop, self).start()\n",
      "  File \"/usr/local/anaconda/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"/usr/local/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/usr/local/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/usr/local/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/usr/local/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/usr/local/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/usr/local/anaconda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/anaconda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/usr/local/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-159-3e4333d5854a>\", line 2, in <module>\n",
      "    cost = tf.reduce_mean(tf.squared_difference(prediction, actual_y))\n",
      "  File \"/usr/local/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 4601, in squared_difference\n",
      "    \"SquaredDifference\", x=x, y=y, name=name)\n",
      "  File \"/usr/local/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n",
      "    op_def=op_def)\n",
      "  File \"/usr/local/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n",
      "    op_def=op_def)\n",
      "  File \"/usr/local/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n",
      "    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Incompatible shapes: [256,1] vs. [6,1]\n",
      "\t [[Node: SquaredDifference = SquaredDifference[T=DT_DOUBLE, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](add_3, _arg_Actual_Y_0_0)]]\n",
      "\n",
      "Epoch:0 Testing Cost: 119.22446392958909\n",
      "CPU times: user 5.98 s, sys: 454 ms, total: 6.44 s\n",
      "Wall time: 4.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with tf.Session() as session:\n",
    "    # Run the global variable initializer to initialize all variables and layers of the neural network\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    # Run the optimizer over and over to train the network.\n",
    "    # One epoch is one full run through the training data set.\n",
    "    epochWiseCost = []\n",
    "    for epoch in range(1):\n",
    "        # Feed in the training data and do one step of neural network training\n",
    "#         session.run(train_iterator.initializer)\n",
    "#         idx = 0\n",
    "#         print('Epoch {}'.format(epoch))\n",
    "#         while True:\n",
    "#             try:\n",
    "#                 batch = train_iterator.get_next()\n",
    "#                 idx = idx + 1\n",
    "#                 feedDict = getFeedDict(batch, batchSize, session)\n",
    "#                 session.run(optimizer, feed_dict=feedDict)\n",
    "#                 print('Batch {} Size: {}'.format(idx, batch[0].eval(session=session).shape[0]))\n",
    "#             except tf.errors.OutOfRangeError:\n",
    "#                 break\n",
    "                \n",
    "        session.run(test_iterator.initializer)\n",
    "        idx = 0\n",
    "        batchWiseCost = []\n",
    "        while True:\n",
    "            try:\n",
    "                batch = test_iterator.get_next()\n",
    "                idx = idx + 1\n",
    "                feedDict = getFeedDict(batch, batchSize, session)\n",
    "                testCost = session.run(cost, feed_dict=feedDict)\n",
    "                print(\"Batch: {} Cost: {}\".format(idx, testCost))\n",
    "                batchWiseCost.append(testCost)\n",
    "            except Exception as e: \n",
    "                print('Exception Occurred', e)\n",
    "                break\n",
    "        epochTestCost = np.array(batchWiseCost).mean()\n",
    "        epochWiseCost.append(epochTestCost)\n",
    "        print(\"Epoch:{} Testing Cost: {}\".format(epoch, epochTestCost))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Required Batch Size: 256, Actual Batch Size: age(256, 1), yop(256, 1), atr(256, 1), city(256, 1), state(256, 1), output(256, 1)\n",
      "Batch 1 Size: 256\n",
      "Required Batch Size: 256, Actual Batch Size: age(256, 1), yop(256, 1), atr(256, 1), city(256, 1), state(256, 1), output(256, 1)\n",
      "Batch 2 Size: 256\n",
      "Required Batch Size: 256, Actual Batch Size: age(256, 1), yop(256, 1), atr(256, 1), city(256, 1), state(256, 1), output(256, 1)\n",
      "Batch 3 Size: 256\n",
      "Required Batch Size: 256, Actual Batch Size: age(256, 1), yop(256, 1), atr(256, 1), city(256, 1), state(256, 1), output(256, 1)\n",
      "Batch 4 Size: 256\n",
      "Required Batch Size: 256, Actual Batch Size: age(256, 1), yop(256, 1), atr(256, 1), city(256, 1), state(256, 1), output(256, 1)\n",
      "Batch 5 Size: 256\n",
      "Required Batch Size: 256, Actual Batch Size: age(256, 1), yop(256, 1), atr(256, 1), city(256, 1), state(256, 1), output(256, 1)\n",
      "Batch 6 Size: 256\n",
      "Required Batch Size: 256, Actual Batch Size: age(256, 1), yop(256, 1), atr(256, 1), city(256, 1), state(256, 1), output(256, 1)\n",
      "Required Batch Size: 256, Actual Batch Size: age(256, 1), yop(256, 1), atr(256, 1), city(256, 1), state(256, 1), output(256, 1)\n",
      "Required Batch Size: 256, Actual Batch Size: age(256, 1), yop(256, 1), atr(256, 1), city(256, 1), state(256, 1), output(256, 1)\n",
      "Required Batch Size: 256, Actual Batch Size: age(256, 1), yop(256, 1), atr(256, 1), city(256, 1), state(256, 1), output(256, 1)\n",
      "Required Batch Size: 256, Actual Batch Size: age(256, 1), yop(256, 1), atr(256, 1), city(256, 1), state(256, 1), output(6, 1)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [256,1] vs. [6,1]\n\t [[Node: SquaredDifference = SquaredDifference[T=DT_DOUBLE, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](add_3, _arg_Actual_Y_0_0)]]\n\nCaused by op 'SquaredDifference', defined at:\n  File \"/usr/local/anaconda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/anaconda/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/anaconda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/anaconda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/anaconda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/anaconda/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/anaconda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/anaconda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-159-3e4333d5854a>\", line 2, in <module>\n    cost = tf.reduce_mean(tf.squared_difference(prediction, actual_y))\n  File \"/usr/local/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 4601, in squared_difference\n    \"SquaredDifference\", x=x, y=y, name=name)\n  File \"/usr/local/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/usr/local/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Incompatible shapes: [256,1] vs. [6,1]\n\t [[Node: SquaredDifference = SquaredDifference[T=DT_DOUBLE, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](add_3, _arg_Actual_Y_0_0)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [256,1] vs. [6,1]\n\t [[Node: SquaredDifference = SquaredDifference[T=DT_DOUBLE, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](add_3, _arg_Actual_Y_0_0)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [256,1] vs. [6,1]\n\t [[Node: SquaredDifference = SquaredDifference[T=DT_DOUBLE, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](add_3, _arg_Actual_Y_0_0)]]\n\nCaused by op 'SquaredDifference', defined at:\n  File \"/usr/local/anaconda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/anaconda/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/anaconda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/anaconda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/anaconda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/anaconda/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/anaconda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/anaconda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-159-3e4333d5854a>\", line 2, in <module>\n    cost = tf.reduce_mean(tf.squared_difference(prediction, actual_y))\n  File \"/usr/local/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 4601, in squared_difference\n    \"SquaredDifference\", x=x, y=y, name=name)\n  File \"/usr/local/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/usr/local/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Incompatible shapes: [256,1] vs. [6,1]\n\t [[Node: SquaredDifference = SquaredDifference[T=DT_DOUBLE, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](add_3, _arg_Actual_Y_0_0)]]\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with tf.Session() as session:\n",
    "    # Run the global variable initializer to initialize all variables and layers of the neural network\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    # Run the optimizer over and over to train the network.\n",
    "    # One epoch is one full run through the training data set.\n",
    "    epochWiseCost = []\n",
    "    for epoch in range(10):\n",
    "        # Feed in the training data and do one step of neural network training\n",
    "        session.run(train_iterator.initializer)\n",
    "        idx = 0\n",
    "        print('Epoch {}'.format(epoch))\n",
    "        while True:\n",
    "            try:\n",
    "                batch = train_iterator.get_next()\n",
    "                idx = idx + 1\n",
    "                feedDict = getFeedDict(batch, batchSize, session)\n",
    "                session.run(optimizer, feed_dict=feedDict)\n",
    "                print('Batch {} Size: {}'.format(idx, batch[0].eval(session=session).shape[0]))\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                break\n",
    "                \n",
    "        session.run(test_iterator.initializer)\n",
    "        idx = 0\n",
    "        batchWiseCost = []\n",
    "        while True:\n",
    "            try:\n",
    "                batch = test_iterator.get_next()\n",
    "                idx = idx + 1\n",
    "                feedDict = getFeedDict(batch, batchSize, session)\n",
    "                batchWiseCost.append(session.run(cost, feed_dict=feedDict))\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                break\n",
    "        epochTestCost = np.array(batchWiseCost).mean()\n",
    "        epochWiseCost.append(epochTestCost)\n",
    "        print(\"Epoch:{} Testing Cost: {}\".format(epoch, epochTestCost))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# train_cost = {};\n",
    "# test_cost = {};\n",
    "# with tf.Session() as session:\n",
    "#     # Create log file writers to record training progress.\n",
    "#     # We'll store training and testing log data separately.\n",
    "#     training_writer = tf.summary.FileWriter(\"./logs/{}/training\".format(RUN_NAME), session.graph)\n",
    "#     testing_writer = tf.summary.FileWriter(\"./logs/{}/testing\".format(RUN_NAME), session.graph)\n",
    "\n",
    "#     # Run the global variable initializer to initialize all variables and layers of the neural network\n",
    "#     session.run(tf.global_variables_initializer())\n",
    "#     # Run the optimizer over and over to train the network.\n",
    "#     # One epoch is one full run through the training data set.\n",
    "#     for epoch in range(training_epochs):\n",
    "#         # Feed in the training data and do one step of neural network training\n",
    "#         # 'Age', 'Year-Of-Publication', 'Book-Author-Enc', 'City-Enc','State-Enc'\n",
    "#         feedDict = getFeedDict(X_train, y_train, True)\n",
    "#         session.run(optimizer, feed_dict=feedDict)\n",
    "#         if epoch % 5 == 0:\n",
    "#             # Get the current accuracy scores by running the \"cost\" operation on the training and test data sets\n",
    "#             feedDict = getFeedDict(X_train, y_train, True)\n",
    "#             training_cost, training_summary = session.run([cost, summary], feed_dict=feedDict)\n",
    "                \n",
    "#             feedDict = getFeedDict(X_test, y_test, True)\n",
    "#             testing_cost, testing_summary = session.run([cost, summary], feed_dict=feedDict)\n",
    "#             # Write the current training status to the log files (Which we can view with TensorBoard)\n",
    "#             training_writer.add_summary(training_summary, epoch)\n",
    "#             testing_writer.add_summary(testing_summary, epoch)\n",
    "#             # Print the current training status to the screen\n",
    "#             train_cost[epoch] = training_cost;\n",
    "#             test_cost[epoch] = testing_cost;\n",
    "#             print(\"Epoch: {} - Training Cost: {}  Testing Cost: {}\".format(epoch, training_cost, testing_cost))\n",
    "#     feedDict = getFeedDict(X_test, y_test, True)\n",
    "#     testing_cost, training_summary = session.run([cost, summary], feed_dict=feedDict)\n",
    "#     print(\"Testing Cost: {}\".format(testing_cost))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ! tensorboard --logdir \"./logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] Batch Size: 256 Total Batch: 10 Last Batch Size: 6\n"
     ]
    }
   ],
   "source": [
    "print('[TEST] Batch Size: {} Total Batch: {} Last Batch Size: {}' . format(batchSize, y_test.shape[0] // batchSize + 1, y_test.shape[0] % batchSize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_t' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-169-405c1d885a4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[TEST] Batch Size: {} Total Batch: {} Last Batch Size: {}'\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatchSize\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatchSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_t' is not defined"
     ]
    }
   ],
   "source": [
    "print('[TEST] Batch Size: {} Total Batch: {} Last Batch Size: {}' . format(batchSize, y_t.shape[0] // batchSize + 1, y_test.shape[0] % batchSize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape[0], X_train.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
