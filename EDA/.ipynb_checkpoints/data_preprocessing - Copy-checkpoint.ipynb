{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import progressbar\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import json_normalize\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CITIES_FILEPATH = '../Dataset/Location/cities.json'\n",
    "STATES_FILEPATH = '../Dataset/Location/states.json'\n",
    "COUNTRIES_FILEPATH = '../Dataset/Location/countries.json'\n",
    "LOCATION_FILEPATH = '../Dataset/Processed/Locations.csv'\n",
    "USERS_FILEPATH = '../Dataset/BX-CSV-Dump/BX-Users.csv'\n",
    "BOOKS_FILEPATH = '../Dataset/BX-CSV-Dump/BX-Books.csv'\n",
    "USERS_NORMALIZED_FILEPATH = '../Dataset/Processed/BX-Users.csv'\n",
    "LOC_FUZZY_MAP_FILEPATH = '../Dataset/Processed/mappings.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = pd.read_csv(BOOKS_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitizeNumericData(row, as_types):\n",
    "    for col in as_types:\n",
    "        row[col] = int(''.join(filter(str.isdigit, row[col]))) if as_types[col] == 'int64' else row[col]\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataframeFromJSON(filepath, key, rename_columns, as_types={}):\n",
    "    with open(filepath) as f: \n",
    "        d = json.load(f)  \n",
    "    return json_normalize(d[key]).apply(sanitizeNumericData, args=(as_types, ), axis=1).rename(columns=rename_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(LOCATION_FILEPATH):\n",
    "    cities = loadDataframeFromJSON(CITIES_FILEPATH, 'cities', {'id': 'city_id', 'name': 'city'}, {'id': 'int64', 'state_id': 'int64'})\n",
    "    states = loadDataframeFromJSON(STATES_FILEPATH, 'states', {'id': 'state_id', 'name': 'state'}, {'id': 'int64','country_id': 'int64'})\n",
    "    countries = loadDataframeFromJSON(COUNTRIES_FILEPATH, 'countries', {'id': 'country_id', 'sortname': 'country_code', 'phoneCode': 'phone_code', 'name': 'country'})\n",
    "    locations = cities.merge(states, on='state_id', how=\"inner\").merge(countries, on='country_id', how=\"inner\")\n",
    "    locations.to_csv(LOCATION_FILEPATH, index=False, index_label=False, columns=['city_id', 'city', 'state_id', 'state', 'country_id', 'country', 'country_code', 'phone_code'])\n",
    "else:\n",
    "    locations = pd.read_csv(LOCATION_FILEPATH);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations['Location'] = locations['city'] + \", \" + locations['state'] + \", \" + locations['country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_id</th>\n",
       "      <th>city</th>\n",
       "      <th>state_id</th>\n",
       "      <th>state</th>\n",
       "      <th>country_id</th>\n",
       "      <th>country</th>\n",
       "      <th>country_code</th>\n",
       "      <th>phone_code</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bombuflat</td>\n",
       "      <td>1</td>\n",
       "      <td>Andaman and Nicobar Islands</td>\n",
       "      <td>101</td>\n",
       "      <td>India</td>\n",
       "      <td>IN</td>\n",
       "      <td>91</td>\n",
       "      <td>Bombuflat, Andaman and Nicobar Islands, India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Garacharma</td>\n",
       "      <td>1</td>\n",
       "      <td>Andaman and Nicobar Islands</td>\n",
       "      <td>101</td>\n",
       "      <td>India</td>\n",
       "      <td>IN</td>\n",
       "      <td>91</td>\n",
       "      <td>Garacharma, Andaman and Nicobar Islands, India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Port Blair</td>\n",
       "      <td>1</td>\n",
       "      <td>Andaman and Nicobar Islands</td>\n",
       "      <td>101</td>\n",
       "      <td>India</td>\n",
       "      <td>IN</td>\n",
       "      <td>91</td>\n",
       "      <td>Port Blair, Andaman and Nicobar Islands, India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Rangat</td>\n",
       "      <td>1</td>\n",
       "      <td>Andaman and Nicobar Islands</td>\n",
       "      <td>101</td>\n",
       "      <td>India</td>\n",
       "      <td>IN</td>\n",
       "      <td>91</td>\n",
       "      <td>Rangat, Andaman and Nicobar Islands, India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Addanki</td>\n",
       "      <td>2</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>101</td>\n",
       "      <td>India</td>\n",
       "      <td>IN</td>\n",
       "      <td>91</td>\n",
       "      <td>Addanki, Andhra Pradesh, India</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   city_id        city  state_id                        state  country_id  \\\n",
       "0        1   Bombuflat         1  Andaman and Nicobar Islands         101   \n",
       "1        2  Garacharma         1  Andaman and Nicobar Islands         101   \n",
       "2        3  Port Blair         1  Andaman and Nicobar Islands         101   \n",
       "3        4      Rangat         1  Andaman and Nicobar Islands         101   \n",
       "4        5     Addanki         2               Andhra Pradesh         101   \n",
       "\n",
       "  country country_code  phone_code  \\\n",
       "0   India           IN          91   \n",
       "1   India           IN          91   \n",
       "2   India           IN          91   \n",
       "3   India           IN          91   \n",
       "4   India           IN          91   \n",
       "\n",
       "                                         Location  \n",
       "0   Bombuflat, Andaman and Nicobar Islands, India  \n",
       "1  Garacharma, Andaman and Nicobar Islands, India  \n",
       "2  Port Blair, Andaman and Nicobar Islands, India  \n",
       "3      Rangat, Andaman and Nicobar Islands, India  \n",
       "4                  Addanki, Andhra Pradesh, India  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadNormalizedUsers():\n",
    "    if not os.path.exists(USERS_NORMALIZED_FILEPATH):\n",
    "        users = pd.read_csv(USERS_FILEPATH, sep=\";\")\n",
    "        users_loc = pd.DataFrame([ x.split(', ', 2)[0:3] for x in users['Location'].tolist() ])\n",
    "        users_loc.columns = ['city', 'state', 'country']\n",
    "        users_normalized = pd.concat([users, users_loc], axis=1)\n",
    "        users_normalized['fuzzy_match'] = np.nan\n",
    "    else:\n",
    "        users_normalized = pd.read_csv(USERS_NORMALIZED_FILEPATH, dtype={'fuzzy_match': str, \"city\": str, \"state\": str})\n",
    "    return users_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "users_normalized = loadNormalizedUsers()\n",
    "users_normalized.loc[120:140]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 278770 entries, 0 to 278857\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   User-ID      278770 non-null  int64  \n",
      " 1   Location     278770 non-null  object \n",
      " 2   Age          168048 non-null  float64\n",
      " 3   city         278210 non-null  object \n",
      " 4   state        265613 non-null  object \n",
      " 5   country      274178 non-null  object \n",
      " 6   fuzzy_match  0 non-null       object \n",
      "dtypes: float64(1), int64(1), object(5)\n",
      "memory usage: 17.0+ MB\n"
     ]
    }
   ],
   "source": [
    "users_normalized.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! conda install -c conda-forge fuzzywuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz, process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPotentialMatch(city, state):\n",
    "    booleans = []\n",
    "    for row in locations.itertuples():\n",
    "        if fuzz.WRatio(city, row.city) > 90:\n",
    "            booleans.append(True)\n",
    "        else:\n",
    "            booleans.append(False)\n",
    "    return booleans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(LOC_FUZZY_MAP_FILEPATH,)  \n",
    "mapping = json.load(f)\n",
    "def fuzzy_match_loc(row):\n",
    "    index = row.city + \"|\" + row.state\n",
    "    if(index not in mapping):\n",
    "        filters = getPotentialMatch(row.city, row.state);\n",
    "        potential_matches = locations[filters]\n",
    "        if potential_matches['Location'].count() > 0:\n",
    "            row.fuzzy_match = process.extractOne(row.Location, list(potential_matches['Location'].values))[0]\n",
    "            mapping[index] = row.fuzzy_match\n",
    "    else:\n",
    "       row.fuzzy_match  = mapping[index]\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7% (19 of 264) |#              | Elapsed Time: 6:17:47 ETA:  2 days, 12:45:50"
     ]
    }
   ],
   "source": [
    "n = 1000\n",
    "chunk=0\n",
    "stop_limit = 20\n",
    "users_normalized = loadNormalizedUsers()\n",
    "to_process_users= users_normalized[users_normalized['fuzzy_match'].isna()].fillna('')\n",
    "total_chunk = to_process_users.shape[0] // n\n",
    "list_df = [to_process_users[i:i+n] for i in range(0,to_process_users.shape[0],n)]\n",
    "for df in progressbar.progressbar(list_df, redirect_stdout=True):\n",
    "    updated_df = df.apply(fuzzy_match_loc, axis=1)\n",
    "    users_normalized.loc[users_normalized['User-ID'].isin(updated_df['User-ID']), ['fuzzy_match']] = updated_df[['fuzzy_match']]\n",
    "    users_normalized.to_csv(USERS_NORMALIZED_FILEPATH, index=False, index_label=False)\n",
    "    saveLocMapping()\n",
    "    chunk=chunk+1\n",
    "    if chunk == stop_limit:\n",
    "        updated_df.head(20)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6171"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveLocMapping():\n",
    "    json_content = json.dumps(mapping)\n",
    "    f = open(LOC_FUZZY_MAP_FILEPATH,\"w\")\n",
    "    f.write(json_content)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278770"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(users_normalized['Location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Age</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>fuzzy_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>nyc, new york, usa</td>\n",
       "      <td></td>\n",
       "      <td>nyc</td>\n",
       "      <td>new york</td>\n",
       "      <td>usa</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>mediapolis, iowa, usa</td>\n",
       "      <td></td>\n",
       "      <td>mediapolis</td>\n",
       "      <td>iowa</td>\n",
       "      <td>usa</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>rio de janeiro, rio de janeiro, brazil</td>\n",
       "      <td>25</td>\n",
       "      <td>rio de janeiro</td>\n",
       "      <td>rio de janeiro</td>\n",
       "      <td>brazil</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>ferrol / spain, alabama, spain</td>\n",
       "      <td>46</td>\n",
       "      <td>ferrol / spain</td>\n",
       "      <td>alabama</td>\n",
       "      <td>spain</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>54</td>\n",
       "      <td>eubank, kentucky, usa</td>\n",
       "      <td>44</td>\n",
       "      <td>eubank</td>\n",
       "      <td>kentucky</td>\n",
       "      <td>usa</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>60</td>\n",
       "      <td>trieste, friuli venezia giulia, italy</td>\n",
       "      <td></td>\n",
       "      <td>trieste</td>\n",
       "      <td>friuli venezia giulia</td>\n",
       "      <td>italy</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>65</td>\n",
       "      <td>n/a, n/a, australia</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>australia</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>84</td>\n",
       "      <td>san diago, california, usa</td>\n",
       "      <td></td>\n",
       "      <td>san diago</td>\n",
       "      <td>california</td>\n",
       "      <td>usa</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>90</td>\n",
       "      <td>powhatan, virginia, usa</td>\n",
       "      <td>42</td>\n",
       "      <td>powhatan</td>\n",
       "      <td>virginia</td>\n",
       "      <td>usa</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>91</td>\n",
       "      <td>toronto/newmarket, ,</td>\n",
       "      <td></td>\n",
       "      <td>toronto/newmarket</td>\n",
       "      <td>,</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User-ID                                Location Age               city  \\\n",
       "0         1                      nyc, new york, usa                    nyc   \n",
       "13       14                   mediapolis, iowa, usa             mediapolis   \n",
       "17       18  rio de janeiro, rio de janeiro, brazil  25     rio de janeiro   \n",
       "20       21          ferrol / spain, alabama, spain  46     ferrol / spain   \n",
       "53       54                   eubank, kentucky, usa  44             eubank   \n",
       "59       60   trieste, friuli venezia giulia, italy                trieste   \n",
       "64       65                     n/a, n/a, australia                          \n",
       "83       84              san diago, california, usa              san diago   \n",
       "89       90                 powhatan, virginia, usa  42           powhatan   \n",
       "90       91                    toronto/newmarket, ,      toronto/newmarket   \n",
       "\n",
       "                    state    country fuzzy_match  \n",
       "0                new york        usa              \n",
       "13                   iowa        usa              \n",
       "17         rio de janeiro     brazil              \n",
       "20                alabama      spain              \n",
       "53               kentucky        usa              \n",
       "59  friuli venezia giulia      italy              \n",
       "64                         australia              \n",
       "83             california        usa              \n",
       "89               virginia        usa              \n",
       "90                      ,                         "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_normalized.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
