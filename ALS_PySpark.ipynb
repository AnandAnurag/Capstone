{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "# spark imports\n",
    "import findspark\n",
    "import pickle\n",
    "findspark.init('C:/Users/Lenovo/Downloads/spark-3.0.0-preview2-bin-hadoop3.2')\n",
    "\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "from pyspark.mllib.recommendation import ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext('local')\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = spark.read.load(r\"C:\\Users\\Lenovo\\Documents\\Springboard\\Capstone\\Dataset\\BX-CSV-Dump\\BX-Books.csv\",\n",
    "                     format=\"csv\", sep=\";\", inferSchema=\"true\", header=\"true\", encoding ='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|book_id|      ISBN|\n",
      "+-------+----------+\n",
      "|      1|0000913154|\n",
      "|      2|0001010565|\n",
      "|      3|0001046438|\n",
      "+-------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "win_row_number = Window.orderBy(\"ISBN\")\n",
    "isbn = books.select(F.row_number().over(win_row_number).alias(\"book_id\"), \"ISBN\")\n",
    "isbn.cache().show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = spark.read.load(r\"C:\\Users\\Lenovo\\Documents\\Springboard\\Capstone\\Dataset\\BX-CSV-Dump\\BX-Book-Ratings.csv\",\n",
    "                     format=\"csv\", sep=\";\", inferSchema=\"true\", header=\"true\", encoding ='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+------+\n",
      "|userID|productID|rating|\n",
      "+------+---------+------+\n",
      "|276725|    46116|   0.0|\n",
      "|276726|    22830|   5.0|\n",
      "|276727|    92994|   0.0|\n",
      "+------+---------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings = ratings.withColumn(\"Book-Rating\", ratings[\"Book-Rating\"].cast(\"Float\"))\n",
    "ratings_with_bid = ratings.join(isbn, on=[\"ISBN\"], how=\"inner\").select(col(\"User-ID\").alias(\"userID\"), col(\"book_id\").alias(\"productID\"), col(\"Book-Rating\").alias(\"rating\"))\n",
    "ratings_with_bid.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+------+\n",
      "|userID|productID|rating|\n",
      "+------+---------+------+\n",
      "|277107|    62084|  10.0|\n",
      "|277523|   109110|  10.0|\n",
      "|  1172|   257519|  10.0|\n",
      "+------+---------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_ratings_with_bid = ratings_with_bid.sample(False, 0.0001, 3)\n",
    "sample_ratings_with_bid.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ALS.train(sample_ratings_with_bid, rank=5, iterations=5, lambda_=0.01, blocks=-1, nonnegative=False, seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendedBookNames(x):\n",
    "    print(x.product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Rating(user=1172, product=257519, rating=9.998900536474139),\n",
       " Rating(user=1172, product=117255, rating=7.642835490199193),\n",
       " Rating(user=1172, product=27203, rating=6.55736177675994),\n",
       " Rating(user=1172, product=250921, rating=5.407352481218171),\n",
       " Rating(user=1172, product=64744, rating=4.225755884348793),\n",
       " Rating(user=1172, product=89231, rating=4.1350484026784144),\n",
       " Rating(user=1172, product=103524, rating=3.9064897578146445),\n",
       " Rating(user=1172, product=138582, rating=3.8655452130343804),\n",
       " Rating(user=1172, product=199279, rating=3.405959692941238),\n",
       " Rating(user=1172, product=253763, rating=2.7431275813945035)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.recommendProducts(1172, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|      ISBN|\n",
      "+----------+\n",
      "|0000913154|\n",
      "|0001010565|\n",
      "|0001046438|\n",
      "|0001046713|\n",
      "|000104687X|\n",
      "|0001046934|\n",
      "|0001047213|\n",
      "|0001047647|\n",
      "|0001047663|\n",
      "|0001047868|\n",
      "+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = model.recommendProducts(1172, 10)\n",
    "for i in x:\n",
    "    print(isbn.filter(isbn['book_id'] = i.product).select(col('ISBN')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-9fd70ae6953c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# save the model to disk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr'C:\\Users\\Lenovo\\Documents\\Springboard\\Capstone\\Model\\ALS\\model.sav'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:/Users/Lenovo/Downloads/spark-3.0.0-preview2-bin-hadoop3.2\\python\\pyspark\\context.py\u001b[0m in \u001b[0;36m__getnewargs__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    340\u001b[0m         \u001b[1;31m# This method is called when attempting to pickle SparkContext, which is always an error:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m         raise Exception(\n\u001b[1;32m--> 342\u001b[1;33m             \u001b[1;34m\"It appears that you are attempting to reference SparkContext from a broadcast \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[1;34m\"variable, action, or transformation. SparkContext can only be used on the driver, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[1;34m\"not in code that it run on workers. For more information, see SPARK-5063.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063."
     ]
    }
   ],
   "source": [
    "# save the model to disk\n",
    "filename = r'C:\\Users\\Lenovo\\Documents\\Springboard\\Capstone\\Model\\ALS\\model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
